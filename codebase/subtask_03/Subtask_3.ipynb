{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TWrhaODMlRnU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0cb575-551b-414c-d1a8-8b3f7020a61e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.0-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.0 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 40.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.0\n"
          ]
        }
      ],
      "source": [
        "### INSTALL TRANSFORMERS PACKAGE\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5JDCXea4ljJ1"
      },
      "outputs": [],
      "source": [
        "### IMPORT REQUIRED PACKAGES\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
        "from sklearn import metrics\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "from keras import layers, Model\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePHw5ncxl_1y",
        "outputId": "193ab983-18c5-4e54-e69f-b3101c8c317f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# cuda device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True) # Whether the model returns all hidden-states.\n",
        "\n",
        "categorical_features = ['INTER1', 'INTER2', 'INTERACTION', 'ADMIN1', 'SOURCE', 'SOURCE_SCALE', 'FATALITIES']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBjsnz8GoLzY",
        "outputId": "d43779f0-7215-4edc-c19d-576b065d7d8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "    model.to(device)\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "beK7Vu88wB7B"
      },
      "outputs": [],
      "source": [
        "# Multi Column Label Encoder for encoding labels across multiple columns\n",
        "class MultiColumnLabelEncoder:\n",
        "    def __init__(self,columns = None):\n",
        "        self.columns = columns # array of column names to encode\n",
        "\n",
        "    def fit(self,X,y=None):\n",
        "        return self # not relevant here\n",
        "\n",
        "    def transform(self,X):\n",
        "        '''\n",
        "        Transforms columns of X specified in self.columns using\n",
        "        LabelEncoder(). If no columns specified, transforms all\n",
        "        columns in X.\n",
        "        '''\n",
        "        output = X.copy()\n",
        "        if self.columns is not None:\n",
        "            for col in self.columns:\n",
        "                output[col] = LabelEncoder().fit_transform(output[col])\n",
        "        else:\n",
        "            for colname,col in output.iteritems():\n",
        "                output[colname] = LabelEncoder().fit_transform(col)\n",
        "        return output\n",
        "\n",
        "    def fit_transform(self,X,y=None):\n",
        "        return self.fit(X,y).transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fY0yOpjKnBm_",
        "outputId": "a934d812-d667-4656-fd45-ece25afc39f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (2,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "# LOAD DATAFRAME\n",
        "filename = '/content/task_3_event_prediction.tsv'\n",
        "dataframe = pd.read_csv(filename, delimiter='\\t')\n",
        "\n",
        "# DATA PREPROCESSING\n",
        "\n",
        "# taking only data for India\n",
        "dataframe = dataframe[dataframe['COUNTRY'] == 'India']\n",
        "\n",
        "# taking only EVENT_DATE, EVENT_TYPE, INTER1, INTER2, INTERACTION, ADMIN1, SOURCE, SOURCE_SCALE, NOTES, FATALITIES\n",
        "dataframe = dataframe[['EVENT_DATE', 'EVENT_TYPE', 'INTER1', 'INTER2', 'INTERACTION', 'ADMIN1', 'SOURCE', \n",
        "                       'SOURCE_SCALE', 'NOTES', 'FATALITIES']]\n",
        "\n",
        "# drop nan values\n",
        "dataframe = dataframe.dropna()\n",
        "dataframe = dataframe.reset_index(drop=True)\n",
        "\n",
        "# convert date to pd.datetime\n",
        "dataframe['EVENT_DATE'] = pd.to_datetime(dataframe['EVENT_DATE'])\n",
        "\n",
        "# encode event type as Protests = 1, Others = 0\n",
        "dataframe['EVENT_TYPE'] = np.where(dataframe['EVENT_TYPE'] == 'Protests', 1, 0)\n",
        "\n",
        "# reducing Inter1 by 1 to make minimum as 0\n",
        "dataframe['INTER1'] = dataframe['INTER1'] - 1\n",
        "\n",
        "# updating values in Interaction\n",
        "# MinMaxScaler to normalize numerical values to between 0 and 1\n",
        "scaler = MinMaxScaler(feature_range=(0, dataframe['INTERACTION'].nunique()))\n",
        "dataframe[['INTERACTION']] = scaler.fit_transform(dataframe[['INTERACTION']])\n",
        "\n",
        "# label encode the admin1, source, source_scale columns\n",
        "dataframe = MultiColumnLabelEncoder(columns = ['ADMIN1', 'SOURCE', 'SOURCE_SCALE']).fit_transform(dataframe)\n",
        "\n",
        "# normalize Fatalities as well. But there are values missing in here. What to do?\n",
        "# MinMaxScaler to normalize numerical values to between 0 and 1\n",
        "scaler = MinMaxScaler(feature_range=(0,dataframe['FATALITIES'].nunique()))\n",
        "dataframe[['FATALITIES']] = scaler.fit_transform(dataframe[['FATALITIES']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5aLYhtnuDOl",
        "outputId": "ff145387-ce76-4dfe-d6ce-e8bc10f253f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(77892, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "### DATAFRAME SHAPE: (77892 * 10)\n",
        "dataframe.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_notes_embeddings(df_notes):\n",
        "  '''\n",
        "  using bert base uncased pretrained model, retrieve the embedding for the notes column\n",
        "  '''\n",
        "  sentence_embeddings = None\n",
        "  for note in df_notes:\n",
        "      # Tokenize our sentence with the BERT tokenizer.\n",
        "      tokenized_text = tokenizer.tokenize(note)\n",
        "      # Map the token strings to their vocabulary indeces.\n",
        "      indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "      segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "      # Convert inputs to PyTorch tensors\n",
        "      tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
        "      segments_tensors = torch.tensor([segments_ids]).to(device)\n",
        "      # Run the text through BERT, and collect all of the hidden states produced\n",
        "      # from all 12 layers. \n",
        "      with torch.no_grad():\n",
        "          outputs = model(tokens_tensor, segments_tensors)\n",
        "\n",
        "          # Evaluating the model will return a different number of objects based on \n",
        "          # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
        "          # becase we set `output_hidden_states = True`, the third item will be the \n",
        "          # hidden states from all layers. See the documentation for more details:\n",
        "          # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "          hidden_states = outputs[2]\n",
        "\n",
        "      # Concatenate the tensors for all layers. We use `stack` here to\n",
        "      # create a new dimension in the tensor.\n",
        "      token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "\n",
        "      token_embeddings.size()\n",
        "      # `hidden_states` has shape [13 x 1 x 22 x 768]\n",
        "\n",
        "      # `token_vecs` is a tensor with shape [22 x 768]\n",
        "      token_vecs = hidden_states[-2][0]\n",
        "\n",
        "      # Calculate the average of all 22 token vectors.\n",
        "      sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "      sentence_embedding = sentence_embedding.view(1, sentence_embedding.size(0))\n",
        "      if sentence_embeddings is None:\n",
        "        sentence_embeddings = sentence_embedding        \n",
        "      else:\n",
        "        sentence_embeddings = torch.cat((sentence_embeddings, sentence_embedding), dim=0)        \n",
        "    \n",
        "  return sentence_embeddings"
      ],
      "metadata": {
        "id": "X-L35KA8u3VD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "SePcvgxNvSEp"
      },
      "outputs": [],
      "source": [
        "def get_entity_embedding_model(df, categorical_columns):\n",
        "  '''\n",
        "  Model to fit an embedded vector of the categorical columns to the event type column.\n",
        "  '''\n",
        "  inputs = []\n",
        "  outputs = []\n",
        "  for c in categorical_columns:\n",
        "    num_unique_vals = int(df[c].nunique())\n",
        "    embed_dim = int(min(np.ceil(num_unique_vals / 2), 50))\n",
        "    inp = layers.Input(shape=(1, ))\n",
        "    out = layers.Embedding(num_unique_vals + 1, embed_dim, name=c)(inp)\n",
        "    #apply dropout here\n",
        "    out = layers.Reshape(target_shape=(embed_dim, ))(out)\n",
        "    inputs.append(inp)\n",
        "    outputs.append(out)\n",
        "  x = layers.Concatenate()(outputs)\n",
        "  x = layers.Dense(300, activation='relu')(x)\n",
        "  x = layers.Dropout(0.3)(x)\n",
        "  y = layers.Dense(1, activation='sigmoid')(x)\n",
        "  model = Model(inputs=inputs, outputs = y)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4MnC9Rbwsib",
        "outputId": "83fb44ed-a757-4e00-94ee-915c6cc702c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4869/4869 [==============================] - 32s 6ms/step - loss: 0.0054\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbbecd5d1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "############### CATEGORICAL EMBEDDING MODEL TRAINING\n",
        "entity_embed_model = get_entity_embedding_model(dataframe, categorical_features)\n",
        "entity_embed_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "entity_embed_model.fit(x = [dataframe.loc[:, f] for f in categorical_features], y = dataframe['EVENT_TYPE'].values, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(tgt_df, seq_len):\n",
        "  '''\n",
        "    Function to concatenate the categorical embedding and notes embedding\n",
        "    tgt_df: target dataframe for which the we are finding the embedding\n",
        "    seq_len: sequence length to zero pad the embedding\n",
        "  '''\n",
        "  ############### EMBEDDINGS FOR CATEGORICAL FEATURES\n",
        "  intermediate_layer_model = Model(inputs = entity_embed_model.input,\n",
        "                                       outputs = entity_embed_model.get_layer(index=-4).output)\n",
        "\n",
        "  categorical_embeddings = intermediate_layer_model([K.constant(tgt_df.loc[:, f]) for f in categorical_features])\n",
        "  categorical_embeddings = torch.tensor(categorical_embeddings.numpy())\n",
        "  categorical_embeddings = categorical_embeddings.to(device)\n",
        "\n",
        "  ############### GET BERT EMBEDDINGS FOR NOTES\n",
        "  notes_embeddings = get_notes_embeddings(tgt_df['NOTES'])  \n",
        "\n",
        "  ############### CONCAT CATEGORICAL EMBEDDING AND NOTES EMBEDDING\n",
        "  embedded_tensor = torch.cat((categorical_embeddings, notes_embeddings), dim=1)\n",
        "\n",
        "  ############### ZERO PADDING IF LENGTH LESS THAN SEQUENCE LENGTH\n",
        "  original_length = embedded_tensor.shape[0]\n",
        "  if(embedded_tensor.shape[0] < seq_len):\n",
        "    rows_count_to_append = seq_len - embedded_tensor.shape[0]\n",
        "    print(f'Notes embedding size: {notes_embeddings.size()}, Categorical embedding size: {categorical_embeddings.size()}, Rows to append: {rows_count_to_append}')\n",
        "    cols = embedded_tensor.shape[1]\n",
        "    new_rows_tensor = torch.zeros(rows_count_to_append, cols).to(device)\n",
        "    embedded_tensor = torch.cat((embedded_tensor, new_rows_tensor), dim=0)\n",
        "  else:\n",
        "    print(f'Notes embedding size: {notes_embeddings.size()}, Categorical embedding size: {categorical_embeddings.size()}')\n",
        "\n",
        "  return embedded_tensor, original_length"
      ],
      "metadata": {
        "id": "dlochPeBSlcg"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############### ROW COUNTS OF DATA GROUPED BY EVENT DATE TO INITIALISE A VALUE FOR SEQUENCE LENGTH\n",
        "event_date_grouping_row_counts = []\n",
        "\n",
        "for label, df in dataframe.groupby('EVENT_DATE'):\n",
        "  event_date_grouping_row_counts.append(df.shape[0])\n",
        "\n",
        "############### DENSITY DISTRIBUTION PLOT OF THE ROW COUNT\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.subplot(1,2,1)\n",
        "sns.distplot(event_date_grouping_row_counts)\n",
        "plt.subplot(1,2,2)\n",
        "sns.distplot([i for i in event_date_grouping_row_counts if i <= 200])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "Gr61qCfSRg0V",
        "outputId": "c26b8efb-b857-4010-cf1d-10f2dd064e39"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########### CALCULATE VALUES FOR EVENT_DATE, PROTEST_COUNTS, TARGET CLASS (index which is mapped to a target class dict), \n",
        "########### EMBEDDING TARGET (mapped to an embedding dict), AND EMBEDDINGS_DICT FOR EACH UNIQUE EVENT_DATE\n",
        "\n",
        "#######################################################\n",
        "#### DICTIONARY OF THE TARGET CLASSES\n",
        "target_classes_dict = dict()\n",
        "i = 0\n",
        "while i<=150:\n",
        "  target_classes_dict[int(i/10)] = f'[{i}, {i+10})'\n",
        "  i = i+10\n",
        "\n",
        "#######################################################\n",
        "\n",
        "min_sequence_length = 10\n",
        "max_sequence_length = 90\n",
        "\n",
        "event_dates = []\n",
        "protest_counts = []\n",
        "target_classes = []\n",
        "embedding_target = []\n",
        "embeddings_dict = dict()\n",
        "i = 0\n",
        "\n",
        "for label, df in dataframe.groupby('EVENT_DATE'):\n",
        "  if(df.shape[0] > max_sequence_length or df.shape[0] < min_sequence_length):\n",
        "    continue\n",
        "  event_dates.append(label.strftime('%m/%d/%Y'))\n",
        "  protest_counts.append(df['EVENT_TYPE'].sum())\n",
        "  target_classes.append(int(df['EVENT_TYPE'].sum()/10))\n",
        "  embedding_target.append(i)\n",
        "  embeddding, seq_len = get_embeddings(df, max_sequence_length)\n",
        "  embeddings_dict[i] = (embeddding, seq_len)\n",
        "  i = i+1"
      ],
      "metadata": {
        "id": "cDDqqGcn0JJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###### EMBEDDING SHAPE SHOULD BE SAME FOR ALL THE EMBEDDINGS AS WE HAVE PADDED THEM WITH ZEROS (seq_len = 90)\n",
        "for idx, i in enumerate(embedding_target):\n",
        "  print(f'embedding shape for {idx} is {((embeddings_dict[i])[0]).shape}')"
      ],
      "metadata": {
        "id": "T73obI7_W9bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.DataFrame(list(zip(event_dates, protest_counts, embedding_target, target_classes)), \n",
        "                        columns =['EVENT_DATE', 'PROTEST_COUNTS', 'EMBEDDING_KEY', 'TARGET_CLASS_KEY'])\n",
        "\n",
        "###### FINAL DATAFRAME, SHAPE: 1368 * 4\n",
        "final_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zp_KeJAHXTpj",
        "outputId": "f360e002-b484-490b-930d-c71fea965441"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      EVENT_DATE  PROTEST_COUNTS  EMBEDDING_KEY  TARGET_CLASS_KEY\n",
              "0     01/01/2018              19              0                 1\n",
              "1     01/02/2018              36              1                 3\n",
              "2     01/03/2018              44              2                 4\n",
              "3     01/04/2018              22              3                 2\n",
              "4     01/05/2018              30              4                 3\n",
              "...          ...             ...            ...               ...\n",
              "1363  01/17/2022              18           1363                 1\n",
              "1364  01/18/2022              29           1364                 2\n",
              "1365  01/19/2022              27           1365                 2\n",
              "1366  01/20/2022              33           1366                 3\n",
              "1367  01/21/2022              13           1367                 1\n",
              "\n",
              "[1368 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-328fb561-7c1a-480a-b5c5-4327e16eb6fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EVENT_DATE</th>\n",
              "      <th>PROTEST_COUNTS</th>\n",
              "      <th>EMBEDDING_KEY</th>\n",
              "      <th>TARGET_CLASS_KEY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01/01/2018</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01/02/2018</td>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01/03/2018</td>\n",
              "      <td>44</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01/04/2018</td>\n",
              "      <td>22</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01/05/2018</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1363</th>\n",
              "      <td>01/17/2022</td>\n",
              "      <td>18</td>\n",
              "      <td>1363</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1364</th>\n",
              "      <td>01/18/2022</td>\n",
              "      <td>29</td>\n",
              "      <td>1364</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1365</th>\n",
              "      <td>01/19/2022</td>\n",
              "      <td>27</td>\n",
              "      <td>1365</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366</th>\n",
              "      <td>01/20/2022</td>\n",
              "      <td>33</td>\n",
              "      <td>1366</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1367</th>\n",
              "      <td>01/21/2022</td>\n",
              "      <td>13</td>\n",
              "      <td>1367</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1368 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-328fb561-7c1a-480a-b5c5-4327e16eb6fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-328fb561-7c1a-480a-b5c5-4327e16eb6fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-328fb561-7c1a-480a-b5c5-4327e16eb6fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, i in enumerate(protest_counts):\n",
        "  print(f'Protests count for day {idx+1}: {i}, Class Interval: {target_classes_dict[target_classes[idx]]}, Target Class: {target_classes[idx]}')"
      ],
      "metadata": {
        "id": "U1jPGOPWRlSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### splitting into input (embed key) and output data (target class key)\n",
        "X_data, Y_data = final_df['EMBEDDING_KEY'], torch.tensor(final_df['TARGET_CLASS_KEY']).to(device)"
      ],
      "metadata": {
        "id": "06K4QCbH4tl7"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "id": "ExxquiAKUlKb"
      },
      "outputs": [],
      "source": [
        "### BATCH SIZE USED IN GRU1 AND GRU2\n",
        "dataloader_batch_size = 16\n",
        "\n",
        "def get_dataloader(x, x_len, y):\n",
        "  '''\n",
        "  Creates the dataloader using the input x, input length x_len and output y.\n",
        "  '''\n",
        "  data = TensorDataset(x, x_len, y)\n",
        "  dataloader = DataLoader(data, batch_size=dataloader_batch_size)\n",
        "  return dataloader\n",
        "\n",
        "def load_data_for_dataloader(x, y):\n",
        "  '''\n",
        "  Load the data into X as seq_len * embedding size.\n",
        "  Returns X, its unpadded length, and Y.\n",
        "  '''\n",
        "  x_embedded_tensors = None\n",
        "  y_embedded_tensors = None\n",
        "  x_len = []\n",
        "  for idx, i in enumerate(x):\n",
        "    embed_dict_tuple = embeddings_dict[i]\n",
        "    embedding_t = (embed_dict_tuple[0])[None, :, :]\n",
        "    y_train = y[idx].repeat(embedding_t.size(0))\n",
        "    if x_embedded_tensors is None:\n",
        "      x_embedded_tensors = embedding_t\n",
        "    else:\n",
        "      x_embedded_tensors = torch.cat((x_embedded_tensors, embedding_t), dim=0)\n",
        "    x_len.append(embed_dict_tuple[1])\n",
        "    if y_embedded_tensors is None:\n",
        "      y_embedded_tensors = y_train\n",
        "    else:\n",
        "      y_embedded_tensors = torch.cat((y_embedded_tensors, y_train), dim=0)\n",
        "  \n",
        "  return x_embedded_tensors, torch.tensor(x_len), y_embedded_tensors\n",
        "\n",
        "split_ratio = 0.80\n",
        "### LOAD THE DATA IN REQD FORMAT TO CREATE THE DATALOADER\n",
        "flatten_x_train, flatten_x_len, flatten_y_train = load_data_for_dataloader(X_data, Y_data)\n",
        "\n",
        "#### TRAINING SET\n",
        "X_training_set = flatten_x_train[:int(flatten_x_train.shape[0]*split_ratio)]\n",
        "X_train_len = flatten_x_len[:int(flatten_x_train.shape[0]*split_ratio)]\n",
        "Y_training_set = flatten_y_train[:int(flatten_x_train.shape[0]*split_ratio)]\n",
        "\n",
        "#### VALIDATION SET\n",
        "X_test_set = flatten_x_train[int(flatten_x_train.shape[0]*split_ratio):]\n",
        "X_test_len = flatten_x_len[int(flatten_x_train.shape[0]*split_ratio):]\n",
        "Y_test_set = flatten_y_train[int(flatten_x_train.shape[0]*split_ratio):]\n",
        "\n",
        "#### TRAIN AND TEST DATALOADERS\n",
        "train_dataloader = get_dataloader(X_training_set.to(device), X_train_len, Y_training_set)\n",
        "test_dataloader = get_dataloader(X_test_set.to(device), X_test_len, Y_test_set)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "  x, x_len, y = batch\n",
        "  print(x.shape, x_len.shape, y.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAYf9FLsuRKN",
        "outputId": "72338d47-d454-4668-9ff8-7ec59141fdbb"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 90, 885]) torch.Size([16]) torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "id": "WtVPknOzVthY"
      },
      "outputs": [],
      "source": [
        "### GRU MODEL 1 WHICH GIVES THE VECTOR REPRESENTATION OF ONE SINGLE DAY.\n",
        "class GRUClassifier1(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_size_1, \n",
        "                 hidden_size_1, \n",
        "                 num_layers_1, \n",
        "                 dropout_1,\n",
        "                 directions_1, \n",
        "                 bidirectional_1,\n",
        "                 batch_size_1):\n",
        "        super().__init__()\n",
        "        ###############################################################\n",
        "        self.input_size_1 = input_size_1\n",
        "        self.dropout_1 = nn.Dropout(dropout_1)\n",
        "        self.directions_1 = directions_1\n",
        "        self.num_layers_1 = num_layers_1\n",
        "        self.hidden_dim_1 = hidden_size_1\n",
        "        self.gru_1 = nn.GRU(input_size=self.input_size_1,\n",
        "                          hidden_size=self.hidden_dim_1,\n",
        "                          num_layers=self.num_layers_1,\n",
        "                          dropout=dropout_1,\n",
        "                          bidirectional=bidirectional_1)        \n",
        "    \n",
        "    def forward(self, x, x_lens):        \n",
        "        ###############################################################\n",
        "        x_1 = x\n",
        "        # x_1: [batch, seq len, emb dim] => [5 * 80 * 810]\n",
        "\n",
        "        # GRU 1\n",
        "        x_1 = x_1.permute(1, 0, 2) # [seq len, batch, emb dim] ==> [80 * 5 * 810]\n",
        "\n",
        "        # Pack padded batch of sequences for RNN module\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(x_1, x_lens.to('cpu'), batch_first=False, enforce_sorted=False)        \n",
        "        \n",
        "        output_1, h_n_1 = self.gru_1(packed)\n",
        "        h_n_1 = self.dropout_1(h_n_1[-1, :, :])\n",
        "        # output_1 => [seq len * batch * hidden dim] ... [80 * 5 * 256]\n",
        "        # h_n_1 => [num layers * batch * hidden dim] ... [2 * 5 * 256]\n",
        "        # print(f'output dim 1: {output_1.shape}, h_n dim 1: {h_n_1.shape}')\n",
        "\n",
        "        return h_n_1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### GRU MODEL 2 WHICH TAKES THE VECTOR REPRESENTATION FOR EVERY DAY IN THE BATCH AND PREDICTS OUTPUT FOR Nth DAY.\n",
        "class GRUClassifier2(nn.Module):\n",
        "  def __init__(self,\n",
        "                input_size_2,\n",
        "                hidden_size_2,\n",
        "                num_layers_2, \n",
        "                dropout_2,\n",
        "                directions_2, \n",
        "                bidirectional_2,\n",
        "                batch_size_2,\n",
        "                classes=2):\n",
        "    super().__init__()\n",
        "    ###############################################################\n",
        "    self.input_size_2 = input_size_2\n",
        "    self.dropout_2 = nn.Dropout(dropout_2)\n",
        "    self.directions_2 = directions_2\n",
        "    self.num_layers_2 = num_layers_2\n",
        "    self.hidden_dim_2 = hidden_size_2\n",
        "    self.gru_2 = nn.GRU(input_size=self.input_size_2,\n",
        "                      hidden_size=self.hidden_dim_2,\n",
        "                      num_layers=self.num_layers_2,\n",
        "                      dropout=dropout_2,\n",
        "                      bidirectional=bidirectional_2)\n",
        "    ###############################################################\n",
        "    self.fc = nn.Linear(self.hidden_dim_2, classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    ###############################################################\n",
        "    #x_2 = (h_n_1[-1, :, :])[None, :, :] # x_2: [batch, seq len, emb dim] => [1 * 5 * 256]\n",
        "    x_2 = x\n",
        "    # GRU 2\n",
        "\n",
        "    # print(f'x_2 initial dim: {x_2.shape}')\n",
        "    x_2 = x_2.permute(1, 0, 2) # [seq len, batch, emb dim] => [5 * 1 * 256]\n",
        "\n",
        "    output_2, h_n_2 = self.gru_2(x_2)\n",
        "    h_n_2 = self.dropout_2(h_n_2[-1, :, :])\n",
        "    # output_2 => [seq len * batch * hidden dim] ... [5 * 1 * 128]\n",
        "    # h_n_2 => [num layers * batch * hidden dim] ... [2 * 1 * 128]\n",
        "    # print(f'output dim 2: {output_2.shape}, h_n dim 2: {h_n_2.shape}')\n",
        "\n",
        "    ###############################################################\n",
        "    fc_input = h_n_2 # [1 * 128]\n",
        "    # print(f'fc input dim: {fc_input.shape}')\n",
        "    out = self.fc(fc_input) # [1 * 6]\n",
        "    # print(f'out shape: {out}')\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "u-tk1UMFU4mA"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### CLASSIFIER MODULE COMBINING GRU 1 AND GRU 2\n",
        "class GRUClassifier(nn.Module):\n",
        "  def __init__(self, \n",
        "               gru_model_1, \n",
        "               gru_model_2,\n",
        "               n_past,\n",
        "               n_future):\n",
        "      super().__init__()\n",
        "      ###############################################################\n",
        "      self.gru_model_1 = gru_model_1\n",
        "      self.gru_model_2 = gru_model_2\n",
        "      self.n_past = n_past\n",
        "      self.n_future = n_future\n",
        "      self.epoch_no = -1\n",
        "      self.unprocessed_x_train = None\n",
        "\n",
        "  def to_sequence(self, gru_1_out):\n",
        "    X_train = None\n",
        "    if(self.unprocessed_x_train is not None):\n",
        "      # dummy_tensor = (torch.zeros(self.unprocessed_x_train.size())).to(device)\n",
        "      dummy_tensor = (self.unprocessed_x_train.clone().detach()).to(device)\n",
        "      gru_1_out = torch.cat((dummy_tensor, gru_1_out), dim=0)\n",
        "      self.unprocessed_x_train = None\n",
        "    \n",
        "    for i in range(self.n_past, gru_1_out.size(0) - self.n_future + 1):\n",
        "      x_train_past = (gru_1_out[(i - self.n_past) : i, :])[None, :, :]\n",
        "      if X_train is None:\n",
        "        X_train = x_train_past\n",
        "      else:\n",
        "        X_train = torch.cat((X_train, x_train_past), dim=0)\n",
        "\n",
        "    row_size = gru_1_out.size(0)\n",
        "    self.unprocessed_x_train = gru_1_out[(row_size - self.n_past - self.n_future + 1):, :]\n",
        "\n",
        "    # X_train = torch.tensor(X_train)\n",
        "    # print(f'X_train size: {X_train.size()}')\n",
        "    return X_train\n",
        "  \n",
        "  def forward(self, x, x_lens, epoch_no):\n",
        "    if self.epoch_no != epoch_no:\n",
        "      self.unprocessed_x_train = None\n",
        "      self.epoch_no = epoch_no\n",
        "\n",
        "    gru_1_out = self.gru_model_1(x, x_lens) # batch size * hidden dim ===> 5 * 256\n",
        "    #print(f'############### GRU MODEL 1 OUTPUT SHAPE: {gru_1_out.shape} ###############')\n",
        "\n",
        "    gru_2_in = self.to_sequence(gru_1_out) # for n_past = 2, n_future = 1; gru_2_in ===> 3 * 2 * 256 ===> seq len = 2, batch size = 3    \n",
        "    #print(f'############### GRU MODEL 2 INPUT SHAPE: {gru_2_in.shape} ###############')\n",
        "\n",
        "    gru_2_out = self.gru_model_2(gru_2_in) # 3 * 6\n",
        "    #print(f'############### GRU MODEL 2 OUTPUT SHAPE: {gru_2_out.shape} ###############')\n",
        "\n",
        "    return gru_2_out"
      ],
      "metadata": {
        "id": "y8zdV_mJA515"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {
        "id": "tXPl5OFxXeli"
      },
      "outputs": [],
      "source": [
        "# number of past days we want to use to predict into the future\n",
        "global_n_past=3\n",
        "# number of days we want to predict into the future  \n",
        "# must be less than batch size\n",
        "# LEAD TIME\n",
        "global_n_future=3\n",
        "\n",
        "##########################################\n",
        "input_size_1 = X_training_set.shape[2]\n",
        "hidden_size_1 = 256\n",
        "num_layers_1 = 2\n",
        "dropout_1 = 0.3\n",
        "directions_1 = 1\n",
        "bidirectional_1 = False\n",
        "batch_size_1 = dataloader_batch_size\n",
        "##########################################\n",
        "input_size_2 = hidden_size_1\n",
        "hidden_size_2 = 128\n",
        "num_layers_2 = 2\n",
        "dropout_2 = 0.4\n",
        "directions_2 = 1\n",
        "bidirectional_2 = False\n",
        "batch_size_2 = dataloader_batch_size\n",
        "##########################################\n",
        "classes = max(final_df['TARGET_CLASS_KEY'])+1\n",
        "##########################################\n",
        "gru_model_1 = GRUClassifier1(input_size_1, hidden_size_1, num_layers_1, dropout_1, directions_1, bidirectional_1, batch_size_1)\n",
        "##########################################\n",
        "gru_model_2 = GRUClassifier2(input_size_2, hidden_size_2, num_layers_2, dropout_2, directions_2, bidirectional_2, batch_size_2,\n",
        "                          classes)\n",
        "##########################################\n",
        "gru_model = GRUClassifier(gru_model_1, gru_model_2, global_n_past, global_n_future)\n",
        "if torch.cuda.is_available():\n",
        "   gru_model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SfxhWQKYXyn",
        "outputId": "6ef0b071-6252-4868-db64-375e14b5b9a5"
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GRUClassifier(\n",
              "  (gru_model_1): GRUClassifier1(\n",
              "    (dropout_1): Dropout(p=0.3, inplace=False)\n",
              "    (gru_1): GRU(885, 256, num_layers=2, dropout=0.3)\n",
              "  )\n",
              "  (gru_model_2): GRUClassifier2(\n",
              "    (dropout_2): Dropout(p=0.4, inplace=False)\n",
              "    (gru_2): GRU(256, 128, num_layers=2, dropout=0.4)\n",
              "    (fc): Linear(in_features=128, out_features=9, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANS8EE4hXnUL",
        "outputId": "a638592e-e271-47b5-e19e-35d52d8c1114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The GRU model has 1,521,033 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The GRU model has {count_parameters(gru_model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {
        "id": "M9vTJrPjXpG9"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optim = torch.optim.AdamW(gru_model.parameters(), lr = 2e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 309,
      "metadata": {
        "id": "StswMbxsX0Bu"
      },
      "outputs": [],
      "source": [
        "# Training function: Performs forward propagation, backpropagation & optimization.\n",
        "# We also implement gradient clipping, which prevents the gradients from exploding\n",
        "def to_sequence(y_train, unprocessed_y_train):\n",
        "  Ytrain = None\n",
        "\n",
        "  if(unprocessed_y_train is not None):\n",
        "    y_train = torch.cat((unprocessed_y_train, y_train), dim=0)\n",
        "\n",
        "  for i in range(global_n_past, y_train.size(0) - global_n_future + 1):\n",
        "    y_train_past = y_train[i + global_n_future - 1: i + global_n_future]\n",
        "    if Ytrain is None:\n",
        "      Ytrain = y_train_past \n",
        "    else:\n",
        "      Ytrain = torch.cat((Ytrain, y_train_past), dim=0)\n",
        "  \n",
        "  row_size = y_train.size(0)\n",
        "  unprocessed_y_train = y_train[(row_size - global_n_past - global_n_future + 1):]\n",
        "\n",
        "  return Ytrain, unprocessed_y_train\n",
        "\n",
        "def train(gru_model, dataloader, optimizer, criterion, epoch_no, clip=1.0):\n",
        "\n",
        "    gru_model.train()\n",
        "\n",
        "    ep_t_loss = 0\n",
        "    batch_num  = 0\n",
        "    pred, tgt = [], []\n",
        "    unprocessed_y_train = None\n",
        "    \n",
        "    for ix, batch in enumerate(dataloader):\n",
        "        x, x_lens, y = batch        \n",
        "        x = x.to(device)\n",
        "        x_lens = x_lens.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        #print(f'\\n############### ITERATION {ix} ###############')\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output_pred = gru_model(x, x_lens, epoch_no)\n",
        "        #print(f'############### OUTPUT PRED SHAPE: {output_pred.shape} ###############')\n",
        "        y_train, unprocessed_y_train = to_sequence(y, unprocessed_y_train)\n",
        "        #print(f'############### Y_TRAIN MODIFIED SHAPE: {y_train.shape} ###############')\n",
        "        # y_train = y\n",
        "        #print(f'Iteration {ix}; Y_Train size: {y_train.size()}')\n",
        "        loss = criterion(output_pred, y_train)\n",
        "        loss.backward()\n",
        "\n",
        "        #gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(gru_model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        #print(f'############### END OF ITERATION {ix} ###############')\n",
        "        ep_t_loss += loss.item()\n",
        "        batch_num += 1\n",
        "        pred.extend(torch.argmax(output_pred, -1).tolist())\n",
        "        tgt.extend(y_train.tolist())\n",
        "\n",
        "    return ep_t_loss/batch_num, metrics.f1_score(tgt, pred, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function: Calculates loss on the validation data.\n",
        "from sklearn import metrics\n",
        "\n",
        "def evaluate(gru_model, dataloader, criterion, optimizer, epoch_no):\n",
        "\n",
        "    model.eval()\n",
        "    ep_t_loss = 0\n",
        "    batch_num  = 0\n",
        "    pred, tgt = [], []\n",
        "    unprocessed_y_test = None\n",
        "    for ix, batch in enumerate(dataloader):\n",
        "        x, x_lens, y = batch\n",
        "        x = x.to(device)\n",
        "        x_lens = x_lens.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = gru_model(x, x_lens, epoch_no)\n",
        "            y_test, unprocessed_y_test = to_sequence(y, unprocessed_y_test)\n",
        "            loss = criterion(output, y_test)\n",
        "\n",
        "            ep_t_loss += loss.item()\n",
        "            batch_num += 1\n",
        "            pred.extend(torch.argmax(output, -1).tolist())\n",
        "            tgt.extend(y_test.tolist())\n",
        "        \n",
        "    return ep_t_loss/batch_num, metrics.f1_score(tgt, pred, average='macro'), pred, tgt"
      ],
      "metadata": {
        "id": "ktjkGywk5z1l"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {
        "id": "tcQNjS0JYI-g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "263dc14e-c98c-48ec-f734-a63c398d460d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 1/100 [00:00<01:32,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 01\n",
            "\tTrain Total Loss: 2.037 | Train F1: 0.078\n",
            "\tVal. Total Loss: 1.980 | Valid F1: 0.082\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/100 [00:01<01:30,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 02\n",
            "\tTrain Total Loss: 1.950 | Train F1: 0.084\n",
            "\tVal. Total Loss: 1.961 | Valid F1: 0.084\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/100 [00:02<01:28,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 03\n",
            "\tTrain Total Loss: 1.934 | Train F1: 0.082\n",
            "\tVal. Total Loss: 1.958 | Valid F1: 0.088\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/100 [00:03<01:26,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 04\n",
            "\tTrain Total Loss: 1.943 | Train F1: 0.077\n",
            "\tVal. Total Loss: 1.948 | Valid F1: 0.084\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 5/100 [00:04<01:25,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 05\n",
            "\tTrain Total Loss: 1.935 | Train F1: 0.078\n",
            "\tVal. Total Loss: 1.938 | Valid F1: 0.084\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/100 [00:05<01:24,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 06\n",
            "\tTrain Total Loss: 1.939 | Train F1: 0.072\n",
            "\tVal. Total Loss: 1.927 | Valid F1: 0.101\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [00:06<01:23,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 07\n",
            "\tTrain Total Loss: 1.920 | Train F1: 0.077\n",
            "\tVal. Total Loss: 1.942 | Valid F1: 0.089\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/100 [00:07<01:22,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 08\n",
            "\tTrain Total Loss: 1.934 | Train F1: 0.078\n",
            "\tVal. Total Loss: 1.938 | Valid F1: 0.101\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/100 [00:08<01:21,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 09\n",
            "\tTrain Total Loss: 1.925 | Train F1: 0.078\n",
            "\tVal. Total Loss: 1.960 | Valid F1: 0.081\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 10/100 [00:09<01:21,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Total Loss: 1.928 | Train F1: 0.071\n",
            "\tVal. Total Loss: 1.948 | Valid F1: 0.067\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/100 [00:09<01:20,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 11\n",
            "\tTrain Total Loss: 1.917 | Train F1: 0.082\n",
            "\tVal. Total Loss: 1.946 | Valid F1: 0.087\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/100 [00:10<01:19,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 12\n",
            "\tTrain Total Loss: 1.918 | Train F1: 0.070\n",
            "\tVal. Total Loss: 1.950 | Valid F1: 0.075\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/100 [00:11<01:17,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 13\n",
            "\tTrain Total Loss: 1.925 | Train F1: 0.079\n",
            "\tVal. Total Loss: 1.940 | Valid F1: 0.092\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 14/100 [00:12<01:16,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 14\n",
            "\tTrain Total Loss: 1.921 | Train F1: 0.077\n",
            "\tVal. Total Loss: 1.959 | Valid F1: 0.067\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 15/100 [00:13<01:16,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Total Loss: 1.913 | Train F1: 0.076\n",
            "\tVal. Total Loss: 1.939 | Valid F1: 0.062\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/100 [00:14<01:15,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 16\n",
            "\tTrain Total Loss: 1.923 | Train F1: 0.066\n",
            "\tVal. Total Loss: 1.932 | Valid F1: 0.078\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/100 [00:15<01:14,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 17\n",
            "\tTrain Total Loss: 1.915 | Train F1: 0.074\n",
            "\tVal. Total Loss: 1.922 | Valid F1: 0.072\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 18/100 [00:16<01:13,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 18\n",
            "\tTrain Total Loss: 1.920 | Train F1: 0.075\n",
            "\tVal. Total Loss: 1.954 | Valid F1: 0.102\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 19/100 [00:17<01:12,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 19\n",
            "\tTrain Total Loss: 1.913 | Train F1: 0.076\n",
            "\tVal. Total Loss: 1.939 | Valid F1: 0.071\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 20/100 [00:18<01:11,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Total Loss: 1.912 | Train F1: 0.073\n",
            "\tVal. Total Loss: 1.939 | Valid F1: 0.071\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/100 [00:18<01:10,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 21\n",
            "\tTrain Total Loss: 1.902 | Train F1: 0.074\n",
            "\tVal. Total Loss: 1.945 | Valid F1: 0.086\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/100 [00:19<01:09,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 22\n",
            "\tTrain Total Loss: 1.894 | Train F1: 0.080\n",
            "\tVal. Total Loss: 1.952 | Valid F1: 0.084\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 23/100 [00:20<01:08,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 23\n",
            "\tTrain Total Loss: 1.881 | Train F1: 0.085\n",
            "\tVal. Total Loss: 1.966 | Valid F1: 0.089\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 24/100 [00:21<01:07,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 24\n",
            "\tTrain Total Loss: 1.859 | Train F1: 0.085\n",
            "\tVal. Total Loss: 1.966 | Valid F1: 0.085\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 25/100 [00:22<01:06,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 25\n",
            "\tTrain Total Loss: 1.843 | Train F1: 0.110\n",
            "\tVal. Total Loss: 1.934 | Valid F1: 0.101\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 26/100 [00:23<01:06,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 26\n",
            "\tTrain Total Loss: 1.803 | Train F1: 0.132\n",
            "\tVal. Total Loss: 1.867 | Valid F1: 0.148\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 27/100 [00:24<01:05,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 27\n",
            "\tTrain Total Loss: 1.775 | Train F1: 0.186\n",
            "\tVal. Total Loss: 1.881 | Valid F1: 0.153\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 28/100 [00:25<01:04,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 28\n",
            "\tTrain Total Loss: 1.762 | Train F1: 0.182\n",
            "\tVal. Total Loss: 1.930 | Valid F1: 0.123\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 29/100 [00:26<01:04,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 29\n",
            "\tTrain Total Loss: 1.763 | Train F1: 0.175\n",
            "\tVal. Total Loss: 1.905 | Valid F1: 0.150\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 30/100 [00:26<01:02,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 30\n",
            "\tTrain Total Loss: 1.738 | Train F1: 0.210\n",
            "\tVal. Total Loss: 2.003 | Valid F1: 0.104\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 31/100 [00:27<01:01,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 31\n",
            "\tTrain Total Loss: 1.707 | Train F1: 0.225\n",
            "\tVal. Total Loss: 1.999 | Valid F1: 0.125\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 32/100 [00:28<01:00,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 32\n",
            "\tTrain Total Loss: 1.676 | Train F1: 0.239\n",
            "\tVal. Total Loss: 2.002 | Valid F1: 0.094\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 33/100 [00:29<00:59,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 33\n",
            "\tTrain Total Loss: 1.666 | Train F1: 0.260\n",
            "\tVal. Total Loss: 2.027 | Valid F1: 0.111\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 34/100 [00:30<00:59,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 34\n",
            "\tTrain Total Loss: 1.648 | Train F1: 0.273\n",
            "\tVal. Total Loss: 1.938 | Valid F1: 0.134\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 35/100 [00:31<00:58,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 35\n",
            "\tTrain Total Loss: 1.641 | Train F1: 0.270\n",
            "\tVal. Total Loss: 1.926 | Valid F1: 0.141\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 36/100 [00:32<00:57,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 36\n",
            "\tTrain Total Loss: 1.611 | Train F1: 0.298\n",
            "\tVal. Total Loss: 2.061 | Valid F1: 0.081\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 37/100 [00:33<00:56,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 37\n",
            "\tTrain Total Loss: 1.642 | Train F1: 0.260\n",
            "\tVal. Total Loss: 1.963 | Valid F1: 0.131\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 38/100 [00:34<00:55,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 38\n",
            "\tTrain Total Loss: 1.563 | Train F1: 0.350\n",
            "\tVal. Total Loss: 1.947 | Valid F1: 0.144\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 39/100 [00:35<00:54,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 39\n",
            "\tTrain Total Loss: 1.530 | Train F1: 0.387\n",
            "\tVal. Total Loss: 2.023 | Valid F1: 0.120\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 40/100 [00:35<00:53,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 40\n",
            "\tTrain Total Loss: 1.505 | Train F1: 0.339\n",
            "\tVal. Total Loss: 2.092 | Valid F1: 0.128\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 41/100 [00:36<00:52,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 41\n",
            "\tTrain Total Loss: 1.501 | Train F1: 0.368\n",
            "\tVal. Total Loss: 2.255 | Valid F1: 0.106\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 42/100 [00:37<00:51,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 42\n",
            "\tTrain Total Loss: 1.460 | Train F1: 0.362\n",
            "\tVal. Total Loss: 2.343 | Valid F1: 0.084\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 43/100 [00:38<00:50,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 43\n",
            "\tTrain Total Loss: 1.458 | Train F1: 0.380\n",
            "\tVal. Total Loss: 2.320 | Valid F1: 0.124\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 44/100 [00:39<00:50,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 44\n",
            "\tTrain Total Loss: 1.462 | Train F1: 0.390\n",
            "\tVal. Total Loss: 2.341 | Valid F1: 0.096\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 45/100 [00:40<00:49,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 45\n",
            "\tTrain Total Loss: 1.396 | Train F1: 0.396\n",
            "\tVal. Total Loss: 2.310 | Valid F1: 0.094\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 46/100 [00:41<00:48,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 46\n",
            "\tTrain Total Loss: 1.355 | Train F1: 0.461\n",
            "\tVal. Total Loss: 2.406 | Valid F1: 0.096\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 47/100 [00:42<00:47,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 47\n",
            "\tTrain Total Loss: 1.309 | Train F1: 0.441\n",
            "\tVal. Total Loss: 2.576 | Valid F1: 0.075\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 48/100 [00:43<00:46,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 48\n",
            "\tTrain Total Loss: 1.280 | Train F1: 0.487\n",
            "\tVal. Total Loss: 2.417 | Valid F1: 0.110\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 49/100 [00:44<00:45,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 49\n",
            "\tTrain Total Loss: 1.200 | Train F1: 0.517\n",
            "\tVal. Total Loss: 2.350 | Valid F1: 0.148\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 50/100 [00:44<00:44,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 50\n",
            "\tTrain Total Loss: 1.158 | Train F1: 0.546\n",
            "\tVal. Total Loss: 2.307 | Valid F1: 0.147\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 51/100 [00:45<00:44,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 51\n",
            "\tTrain Total Loss: 1.166 | Train F1: 0.515\n",
            "\tVal. Total Loss: 2.308 | Valid F1: 0.154\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 52/100 [00:46<00:43,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 52\n",
            "\tTrain Total Loss: 1.102 | Train F1: 0.523\n",
            "\tVal. Total Loss: 2.397 | Valid F1: 0.193\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 53/100 [00:47<00:42,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 53\n",
            "\tTrain Total Loss: 1.052 | Train F1: 0.560\n",
            "\tVal. Total Loss: 2.436 | Valid F1: 0.160\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 54/100 [00:48<00:41,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 54\n",
            "\tTrain Total Loss: 1.031 | Train F1: 0.557\n",
            "\tVal. Total Loss: 2.475 | Valid F1: 0.144\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 55/100 [00:49<00:40,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 55\n",
            "\tTrain Total Loss: 1.018 | Train F1: 0.549\n",
            "\tVal. Total Loss: 2.625 | Valid F1: 0.133\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 56/100 [00:50<00:39,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 56\n",
            "\tTrain Total Loss: 0.993 | Train F1: 0.552\n",
            "\tVal. Total Loss: 2.649 | Valid F1: 0.131\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 57/100 [00:51<00:38,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 57\n",
            "\tTrain Total Loss: 1.003 | Train F1: 0.574\n",
            "\tVal. Total Loss: 2.617 | Valid F1: 0.129\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 58/100 [00:52<00:37,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 58\n",
            "\tTrain Total Loss: 0.967 | Train F1: 0.624\n",
            "\tVal. Total Loss: 2.512 | Valid F1: 0.190\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 59/100 [00:52<00:36,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 59\n",
            "\tTrain Total Loss: 0.911 | Train F1: 0.603\n",
            "\tVal. Total Loss: 2.675 | Valid F1: 0.129\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 60/100 [00:53<00:35,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 60\n",
            "\tTrain Total Loss: 0.903 | Train F1: 0.607\n",
            "\tVal. Total Loss: 2.646 | Valid F1: 0.154\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 61/100 [00:54<00:34,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 61\n",
            "\tTrain Total Loss: 0.894 | Train F1: 0.628\n",
            "\tVal. Total Loss: 2.870 | Valid F1: 0.103\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 62/100 [00:55<00:34,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 62\n",
            "\tTrain Total Loss: 0.905 | Train F1: 0.592\n",
            "\tVal. Total Loss: 3.011 | Valid F1: 0.125\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 63/100 [00:56<00:33,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 63\n",
            "\tTrain Total Loss: 0.840 | Train F1: 0.630\n",
            "\tVal. Total Loss: 2.833 | Valid F1: 0.134\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 64/100 [00:57<00:32,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 64\n",
            "\tTrain Total Loss: 0.819 | Train F1: 0.666\n",
            "\tVal. Total Loss: 2.739 | Valid F1: 0.166\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 65/100 [00:58<00:31,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 65\n",
            "\tTrain Total Loss: 0.808 | Train F1: 0.662\n",
            "\tVal. Total Loss: 2.596 | Valid F1: 0.160\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 66/100 [00:59<00:30,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 66\n",
            "\tTrain Total Loss: 0.757 | Train F1: 0.680\n",
            "\tVal. Total Loss: 2.843 | Valid F1: 0.208\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 67/100 [01:00<00:29,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 67\n",
            "\tTrain Total Loss: 0.742 | Train F1: 0.695\n",
            "\tVal. Total Loss: 3.003 | Valid F1: 0.165\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 68/100 [01:00<00:28,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 68\n",
            "\tTrain Total Loss: 0.733 | Train F1: 0.732\n",
            "\tVal. Total Loss: 3.041 | Valid F1: 0.137\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 69/100 [01:01<00:27,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 69\n",
            "\tTrain Total Loss: 0.706 | Train F1: 0.764\n",
            "\tVal. Total Loss: 2.934 | Valid F1: 0.117\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 70/100 [01:02<00:26,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 70\n",
            "\tTrain Total Loss: 0.679 | Train F1: 0.715\n",
            "\tVal. Total Loss: 2.928 | Valid F1: 0.126\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 71/100 [01:03<00:25,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 71\n",
            "\tTrain Total Loss: 0.675 | Train F1: 0.712\n",
            "\tVal. Total Loss: 2.891 | Valid F1: 0.131\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 72/100 [01:04<00:25,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 72\n",
            "\tTrain Total Loss: 0.662 | Train F1: 0.773\n",
            "\tVal. Total Loss: 2.944 | Valid F1: 0.130\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 73/100 [01:05<00:24,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 73\n",
            "\tTrain Total Loss: 0.695 | Train F1: 0.778\n",
            "\tVal. Total Loss: 3.087 | Valid F1: 0.170\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 74/100 [01:06<00:23,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 74\n",
            "\tTrain Total Loss: 0.643 | Train F1: 0.804\n",
            "\tVal. Total Loss: 3.084 | Valid F1: 0.148\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 75/100 [01:07<00:22,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 75\n",
            "\tTrain Total Loss: 0.625 | Train F1: 0.783\n",
            "\tVal. Total Loss: 3.143 | Valid F1: 0.124\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 76/100 [01:08<00:21,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 76\n",
            "\tTrain Total Loss: 0.638 | Train F1: 0.780\n",
            "\tVal. Total Loss: 2.965 | Valid F1: 0.140\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 77/100 [01:09<00:20,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 77\n",
            "\tTrain Total Loss: 0.648 | Train F1: 0.802\n",
            "\tVal. Total Loss: 2.980 | Valid F1: 0.152\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 78/100 [01:10<00:19,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 78\n",
            "\tTrain Total Loss: 0.610 | Train F1: 0.776\n",
            "\tVal. Total Loss: 3.074 | Valid F1: 0.121\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 79/100 [01:10<00:18,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 79\n",
            "\tTrain Total Loss: 0.601 | Train F1: 0.829\n",
            "\tVal. Total Loss: 2.877 | Valid F1: 0.131\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 80/100 [01:11<00:18,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 80\n",
            "\tTrain Total Loss: 0.583 | Train F1: 0.791\n",
            "\tVal. Total Loss: 3.058 | Valid F1: 0.143\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 81/100 [01:12<00:17,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 81\n",
            "\tTrain Total Loss: 0.597 | Train F1: 0.783\n",
            "\tVal. Total Loss: 2.985 | Valid F1: 0.147\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 82/100 [01:13<00:16,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 82\n",
            "\tTrain Total Loss: 0.564 | Train F1: 0.849\n",
            "\tVal. Total Loss: 2.971 | Valid F1: 0.155\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 83/100 [01:14<00:15,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 83\n",
            "\tTrain Total Loss: 0.569 | Train F1: 0.813\n",
            "\tVal. Total Loss: 2.990 | Valid F1: 0.144\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 84/100 [01:15<00:14,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 84\n",
            "\tTrain Total Loss: 0.531 | Train F1: 0.797\n",
            "\tVal. Total Loss: 3.089 | Valid F1: 0.108\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 85/100 [01:16<00:13,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 85\n",
            "\tTrain Total Loss: 0.558 | Train F1: 0.849\n",
            "\tVal. Total Loss: 3.231 | Valid F1: 0.157\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 86/100 [01:17<00:12,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 86\n",
            "\tTrain Total Loss: 0.518 | Train F1: 0.844\n",
            "\tVal. Total Loss: 3.138 | Valid F1: 0.173\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 87/100 [01:18<00:11,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 87\n",
            "\tTrain Total Loss: 0.545 | Train F1: 0.835\n",
            "\tVal. Total Loss: 2.964 | Valid F1: 0.146\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 88/100 [01:18<00:10,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 88\n",
            "\tTrain Total Loss: 0.562 | Train F1: 0.823\n",
            "\tVal. Total Loss: 3.083 | Valid F1: 0.114\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 89/100 [01:19<00:09,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 89\n",
            "\tTrain Total Loss: 0.528 | Train F1: 0.800\n",
            "\tVal. Total Loss: 2.988 | Valid F1: 0.145\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 90/100 [01:20<00:08,  1.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 90\n",
            "\tTrain Total Loss: 0.516 | Train F1: 0.832\n",
            "\tVal. Total Loss: 3.049 | Valid F1: 0.144\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 91/100 [01:21<00:08,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 91\n",
            "\tTrain Total Loss: 0.510 | Train F1: 0.840\n",
            "\tVal. Total Loss: 3.059 | Valid F1: 0.170\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 92/100 [01:22<00:07,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 92\n",
            "\tTrain Total Loss: 0.483 | Train F1: 0.871\n",
            "\tVal. Total Loss: 3.240 | Valid F1: 0.145\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 93/100 [01:23<00:06,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 93\n",
            "\tTrain Total Loss: 0.476 | Train F1: 0.868\n",
            "\tVal. Total Loss: 3.063 | Valid F1: 0.171\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 94/100 [01:24<00:05,  1.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 94\n",
            "\tTrain Total Loss: 0.502 | Train F1: 0.868\n",
            "\tVal. Total Loss: 3.019 | Valid F1: 0.146\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 95/100 [01:25<00:04,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 95\n",
            "\tTrain Total Loss: 0.490 | Train F1: 0.867\n",
            "\tVal. Total Loss: 3.227 | Valid F1: 0.172\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 96/100 [01:26<00:03,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 96\n",
            "\tTrain Total Loss: 0.477 | Train F1: 0.863\n",
            "\tVal. Total Loss: 3.159 | Valid F1: 0.116\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 97/100 [01:27<00:02,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 97\n",
            "\tTrain Total Loss: 0.476 | Train F1: 0.848\n",
            "\tVal. Total Loss: 3.144 | Valid F1: 0.154\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 98/100 [01:28<00:01,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 98\n",
            "\tTrain Total Loss: 0.445 | Train F1: 0.844\n",
            "\tVal. Total Loss: 3.058 | Valid F1: 0.158\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 99/100 [01:28<00:00,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 99\n",
            "\tTrain Total Loss: 0.474 | Train F1: 0.882\n",
            "\tVal. Total Loss: 3.013 | Valid F1: 0.141\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [01:29<00:00,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Epoch: 100\n",
            "\tTrain Total Loss: 0.432 | Train F1: 0.879\n",
            "\tVal. Total Loss: 3.198 | Valid F1: 0.136\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "best_valid_loss = float('inf')\n",
        "tot_t_loss, tot_v_loss =[],[]\n",
        "tr_f1_score, val_f1_score = [], []\n",
        "N_EPOCHS = 100\n",
        "\n",
        "for epoch in tqdm(range(N_EPOCHS)): \n",
        "\n",
        "    tr_l, tr_f1= train(gru_model, train_dataloader, optim, criterion, epoch/2)\n",
        "    tot_t_loss.append(tr_l)\n",
        "    tr_f1_score.append(tr_f1)\n",
        "\n",
        "    val_l, val_f1, pred, tgt = evaluate(gru_model, test_dataloader, criterion, optim, (epoch/2)+1)\n",
        "    tot_v_loss.append(val_l)\n",
        "    val_f1_score.append(val_f1)\n",
        "    \n",
        "    # if val_l < best_valid_loss:\n",
        "    #     best_valid_loss = val_l\n",
        "    #     best_pred, best_tgt = pred, tgt\n",
        "    #     torch.save(model.state_dict(), 'model_least_loss.pt')\n",
        "    #     print(\"\\nBest Model Saved !!\")\n",
        "    # elif epoch % 3 == 0:\n",
        "    #     torch.save(model.state_dict(), 'model_checkpoint_'+str(epoch)+'.pt')\n",
        "    #     print(\"\\Checkpoint Model Saved !!\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(f'Epoch: {epoch+1:02}')\n",
        "    print(f'\\tTrain Total Loss: {tr_l:.3f} | Train F1: {tr_f1:.3f}')\n",
        "    print(f'\\tVal. Total Loss: {val_l:.3f} | Valid F1: {val_f1:.3f}')\n",
        "    print(\"_________________________________________________________________\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(val_f1_score), val_f1_score.index(max(val_f1_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ev2Mu-F6QiA",
        "outputId": "2207e9b2-b2e9-4337-fec5-480f406f6da1"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.20766308754924667, 65)"
            ]
          },
          "metadata": {},
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_f1_score[val_f1_score.index(max(val_f1_score))]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RbBUCLS7c5q",
        "outputId": "ad8e2590-6ee4-465e-f5e8-5940a4508934"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6802822052875399"
            ]
          },
          "metadata": {},
          "execution_count": 313
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(tot_t_loss, label='tot_t_loss')\n",
        "plt.plot(tot_v_loss, label = 'tot_v_loss')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "_62cOUBXmqKt",
        "outputId": "d8bed2c4-2efa-48e4-98ec-c28eb0b82ec6"
      },
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbc094f9b50>"
            ]
          },
          "metadata": {},
          "execution_count": 314
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd1xUV9rA8d+hIyAdVBBBxd7F3k1MNM0ka2ISN1HT26Zs+rv7JqubZE02b7Lpxk00PWpiitEkpmg0dlHB3kAUEBVBEKXDef84g6K0AQYHhuf7+cxnmHvP3Hsuo88cnnuK0lojhBCi6XOydwWEEELYhgR0IYRwEBLQhRDCQUhAF0IIByEBXQghHISLvU4cFBSkIyMj7XV6IYRokjZv3nxCax1c2T67BfTIyEhiY2PtdXohhGiSlFKHqtonKRchhHAQEtCFEMJBSEAXQggHYbccemWKiopISUkhPz/f3lVxCB4eHoSHh+Pq6mrvqgghLoJGFdBTUlLw8fEhMjISpZS9q9Okaa3JyMggJSWFqKgoe1dHCHERNKqUS35+PoGBgRLMbUApRWBgoPy1I0Qz0qgCOiDB3IbkdylE89LoAroQQthNZiLs/cnetagzCehCiKanMBc+ugYO/mHb4y5/ARZMgcIzVZfJzYTV/4HiAtue2wYkoJeTlZXFO++8U22ZpKQkPv/882rLxMXF8cMPP1Rb5sMPP+TBBx+sdR2FEEDiCji4En59Dmy1SI/WcGgtlBZD8oaqy23/0pz3j/+zzXltSAJ6ORczoAsh6mGP5f9X6mZIWm2bY55Mgpwj5uekNVWXS91snv94FY7tqv15fv0H7P+19u+zQqPqtljejO93suvIKZses1ubljx3dfcq9z/99NMkJCTQp08fxo0bB8CPP/6IUoq///3vTJ48maeffprdu3fTp08fpk6dyqOPPnreMQoLC3n22WfJy8tj9erVPPPMM0yePLnaeiUlJXH77bdz4sQJgoODmTdvHhEREXz55ZfMmDEDZ2dnfH19WbVqFTt37mT69OkUFhZSWlrKokWLiI6Orv8vR4imorQE9v0EXa+Gwxtg9WsQNaL+xz28zjy3CIRDNQT0iKFwYh8s/gvc8TM4OVt3jryTpr6uXhB9af3rfAFpoZcza9YsOnToQFxcHIMHDyYuLo74+Hh+/fVXnnjiCdLS0pg1axYjRowgLi6uQjAHcHNzY+bMmUyePJm4uLgagznAX/7yF6ZOncq2bduYMmUKDz30EAAzZ85k2bJlxMfHs3jxYgBmz57Nww8/TFxcHLGxsYSHh9v2lyBEY5eyCXJPQPfrYMj9kPAbHImr/3EPrQEPP+hzC6TEmjz9hfJOQsYB6HgJTHgJUmNhw3vWn+OwJZXTbkj961uJRttCr64lfTGsXr2am2++GWdnZ0JDQxk1ahSbNm2iZcuWNj/XunXr+PrrrwG49dZbefLJJwEYNmwY06ZN48Ybb+T6668HYMiQIbzwwgukpKRw/fXXS+tcND97loKTK3S0tHD/eBXW/Adu+LB+xz20DtoNhcgRsPZN88XRftT5ZY5sNc9h/aD9GNi2AJb/E4pyoeck8I+s/hyH15m6t+lXv7pWQVrojdjs2bN5/vnnSU5Opn///mRkZHDLLbewePFiPD09ueKKK1i+fLm9qymas9h5DZYPrtLeHyByOHj4mseAO2DXd5CRUPdj5hyDzAQT0CMGg3KqPO2SusU8t+kLSsFV/zHBefk/4fXeMHc8ZKdUfZ7D66FNH3BrUfe6VkMCejk+Pj7k5OQAMGLECBYsWEBJSQnp6emsWrWKgQMHnlfGmuNYY+jQocyfPx+Azz77jBEjTD4wISGBQYMGMXPmTIKDg0lOTiYxMZH27dvz0EMPMXHiRLZt21bHqxWinvb8AEsegRXPX7xzpu8zKY8uV57bNvh+UM6w5eO6H/fwWvMcMdR8SbTqWfmN0dQtENgRPP3Na98wmL4UHtkOl/7DpH5++2fl5yjKhyNbIKJh0i0gAf08gYGBDBs2jB49erBu3Tp69epF7969GTt2LC+//DKtWrWiV69eODs707t3b1577bVKjzNmzBh27dpFnz59WLBgQY3nffPNN5k3bx69evXik08+4fXXXwfgiSeeoGfPnvTo0YOhQ4fSu3dvFi5cSI8ePejTpw87duzgtttus+nvQAirZKfAd/eblmxaPBRY34Cpl72W3i2dJ5zb5h0CYf3r19vl0Fpzo7J1L/M6coRJuRSVmzpDa5MzD+tf8f1+ETD8URh4J2xfCOl7K5Y5sgVKChs0oKO1tsujf//++kK7du2qsE3Uj/xOhc0VF2n9weVav9BG643/1fq5llrv++XinPv9cVq/O7zi9l9nav0Pf63zT9XtuO8M1fqjiede715qruvgH+e2ZaWYbetnV32c0+laP99a64VTK+5b9Yp5/+kTdaujBRCrq4ir0kIXQlRPa1j6GHxxC3z/MHw1zdzcu+o16H0zOLnAIRv1Ba9OzjFI3nh+uqVM5HDQJed6kZRJiYXMg9UfN+8kHNtp8udl2g0B1Plpl7L+55W10Mt4BcHge2HnN3B0x/n7Dq2DoM7gFVh9fepBAno9LFu2jD59+pz3uO66684rM2/evAplHnjgATvVWIg6SN8Lm943qZU9S03ufOA90OtGcPMyNwirG4gT9zn88GT96xE7F9DQY1LFfW0Hmt4jSeWmAijKg0+ug6+mVz+a9PAGc9zyAd3TH0J7nP9FlbrZfHmF9qi+nkMeBPeW8Pu/zm0rLTFfRg3UXbFMo+222BRcfvnlXH755dWWmT59OtOnT79INRKiAexdap7v/AVatoHSUnAq1xZsNwzWvWXmP3HzOv+9hbnw89/N/CeX/C+4+5zbd2yX6fY39n/BuYZQVJRvvlQ6jYegjhX3u3lVzKPvWQoFp0xXw6TV5w8+Ki2FjP1miH/c5+bL4MKWd+Rw8yVyJM70TDmyxQRzV4/q69oiAIY8YAL6oXUmiB/fDQXZDZs/R1roQjQPOcdg62empVhbe380rfCWbcxrpwvCRuRwM/9JyqaK7437DHIzAH0uZVEm9gPTfzx2bs112L7QDCYafH/VZSKHm+BdcNq83rYAfNqAVzCsef1cudJSmH8zvD3QjPRM32MGKLl6nn+8IQ+YG66fXGv+OkndWn26pbzB94NfO3OeYzvPjUKNGGzd++uoxoCulPJQSm1USsUrpXYqpWZUUsZdKbVAKXVAKbVBKRXZEJUVQtTBif3wwaWmV8reWs4xlHPM5KE7X1F1mbaDTG+XC9MuJcVmgE5ZiuLCgH/IEuSWPw+nj1d9fK1h3TvmOFEjqy5XlkdPXm/qfeA36D3ZpIcO/GICK8D6d8zUASMegwc2wZMHYdzMisfzawtTvze9X+ZOgMIc6wO6R0uYuhhcPOHjibD9K/Pl4tfOuvfXkTUt9AJgrNa6N9AHGK+UuvBr5g7gpNa6I/Aa8JJtqylEM5W+10waVVfJm+CDy0w+2SvEutZwefuXAfr8boIX8mgJrXtXHIiz61vIOgSjnzE3A5PLBfTcTDi+E3rdZEZZ/vJc1cdPXAHpuy39zatZtKXtQJPjTloNO74ywb3XTWbgkWsL8+WStg1+mwGdrzSpnuBO1R8zIAqmfQ+efuZ1WC1GePpHwm3fmS+k5PWWAUsNu+hMjQG9rDOO5aWr5XHhHYaJwEeWn78CLlGyXI4Q9aM1fHYDfFvHm+gpm+Gjq81AmTt+hgF3QsJys4iDtfb+CL5ta74R2G6YacmX9dvW2qRTgjqZ1n34ANNCL7s5eXi9ee4/FYb+BeI/P9div9C6d8yXUc9KboaWVz6PHj/fpIlCupicdr/bzLS3X041NzyvedP64BrQHqb/CNe+C8FdrHtPmeBOJqj7R0KP62v33jqwKoeulHJWSsUBx4FftNYXThYcBiQDaK2LgWygQt8cpdTdSqlYpVRsenp6/WreAGw1fW5tyLzookrHdpgWbspG08Kura2fmBbrHb+YoNTvVjOicvOH1r2/MBcSVpjWeU3Br90wKCkwA2/ATJh1dDsMfcjk3NsOgLzMc18mh9aAs5sZNj/ycWgZDkseNa34sqCfcxR+nWHSJQPvAhf3muscOdx8sRzdZlrnZQbfb46bmQjXza5910H/dmbSrrq0U1v1gIfjzeyQDcyqgK61LtFa9wHCgYFKqRq+rqs8zhytdYzWOiY4OLguh2hQ9gjoQlRpj6V3SUmhCVK1obUJqlEjwdvyf61lGxOct35q3Wo7ib9DcV71+fMyZf22178Ln99kHi3DTNdGMC10OJdHP7wOwmJMjxE3L9OnPTPR5Pr/0xPmT4HXepipZrtNhEH3WHfdkcMBbb7Ievzp3Hb/dmZo/oR/Q4ex1h2rCapVt0WtdZZSagUwHijfaz4VaAukKKVcAF8go141+/Fp8w1vS616woRZVe62xXzoAIMHD+aDDz6ge3czY+To0aN55ZVXiImJqbZ6Mi+6OM+epRDSzXR5O7S2dnN+ZyZC1mHTQi4v5nbYswR2f19zCmPvD6Y/dbthNZ/P098Mm9+zxNz8G3yvOVdZqzq4C7j5WAYGXWW6Ag4v93+n02XwxH7Tx33nN6Y7Yf9pMPg+COxg/XW3HWSZifGSc19kZYY9VPl7HEiNAV0pFQwUWYK5JzCOijc9FwNTgXXAJGC5ZYhqkzJr1ix27NhBXFwcixYtYvbs2cTHx3PixAkGDBjAyJEjmTVrFq+88gpLliyp8jiTJ09m4cKFzJgxg7S0NNLS0moM5nBuXvSpU6cyd+5cHnroIb799tuz86KHhYWRlZUFnJsXfcqUKRQWFlJSUofuaKLxyko2aYNLZ5gbfIdWA09Z//4EyyycF7ZG248x+dzYudUH9KJ80xOk46Xg4mbdOf80F04fMzf/LlzwwcnZ3FBM2WRSSLqk4iAbD1/oc7N51JWbF9w8v/K+6s2ANS301sBHSilnTIpmodZ6iVJqJmZOgcXAB8AnSqkDQCZwU9WHs1I1LemLoT7zod94441cdtllzJgxg4ULFzJpUg0tIQuZF12ctfdH89zlSpNL3vwhFBdaH1wTlpvAfWHr1skJ+k83a2LOHmFmDgzuYnLULQJMGa1NPvtMOvT9s/V1DupYfSBtO9DMXX7gN9PNse0g649dGw2wElBTYU0vl21a675a615a6x5a65mW7c9agjla63yt9Q1a645a64Fa61rcRnc8YWFhBAYGsm3bNhYsWGDVqkXVkXnRm6E9S0wPkaBoMyS9OO/c4go1KSmCg6uqzhUPvAuG/xW8Q80xV86C9y8x/dXB9NOO/xxGPW1SF7YSPtC0zLd8DK16nT9qVNiEjBQtx1bzoYNJu7z88stkZ2fTq1cvq84v86ILAPKyTC+QspuRZXOMWDsBVsomKDxddUB384JLn4M/fwUPx8H0nyD/FPz3Elj5shmq3/VqGFWLFI81wi1px4JT1uXlRa1JQC/HVvOhA0yaNIn58+dz4403Wn1+mRddALD/FzOUvmxWQa8gkxY5tNa69ycsN90TqxtVWV7EILh7BfiGw4oXzI3Ya2dXHOJfXy0CTIoHGnySquZK2eveZUxMjI6NPb8r1u7du+natatd6uOo5HfaBC2caoL3Y3vPBdUlfzVzkzx1qOaJrP471vT0uGNZ7c5bkAMb50CvySa4N4Rv7oX4L+CJBPNFJWpNKbVZa11pLwtpoQvRmGgNB1dC9GUXzGg41KRRjsZX//7cTLNMWl36Wrv7mPlNGiqYAwx72KzDKcG8Qcj0ufWwbNkynnrq/DxjVFQU33zzTYWy8+bNO5tCKTNs2DDefvvtBq2jaGKyk82CCxfOGVKWcz60tvoJohJ/B3TjHTwT0tU8RINodAFda01TmQbGmvnQy9hjXvQmOBRApFla4K17n7+9ZWszfP/gKjP3SVWSN5jZAdv0bbg6ikarUaVcPDw8yMjIkEBkA1prMjIy8PCoYTJ+0bikxZsbmqHdK+7rejUc+LX6JdWO7TQt4Jry7MIhNapPPTw8nJSUFBrjxF1NkYeHB+HhDZgPFbaXFg/BnSsutgAw6D4zV8q6t+DK/6u4X2sT0Lte1fD1FI1Sowrorq6uREVF2bsaQthPWnzV+e+WrU0PlK2fmkE/F85VcvqYmdEwpJLWvWgWGlXKRYhmLeeoCcoX5s/LG/awmSlxw+yK+8pW5KksXSOaBQnoQjQWVd0QLS8o2gw42vRf02+8vOO7zLME9GZLAroQjUVZQG/Vs/pywx+F/GzY/NH524/tAu9W5ybZEs2OBHQhGou0eDM0vqZJq8JjoN1wM6qzfI+wYzsgtFvD1lE0ahLQhWgs0rZVn24pr9eNZnm6srx5SbFZUFrSLc2aBHQhGoPcTMg+bH1A7zQeUGZVITArFJUUSA+XZk4CuhCNgTU3RMvzCTWpl7KAfsyyIqSkXJo1CehC2IPWZt3crZ+an8/eELVu7nzAzJd+ZCucOmJ6uChnCOrcMPUVTUKjGlgkRLNxbCdseNf8vPMbs8qQb0Tteqh0vgJ+m2Fa6cd2mRuqrjLVQ3MmLXQhbKmkCDb+16z+s2tx1eUSfzfPo542MygeXAmta9E6BzNFQEB7s/7o8Z2SbhES0IWwCa1hx9fw9kD44XFzk3LhrfDdg1BwumL5xN8hMBrGPAP3rYEef4J+U2t3TqVMKz1xJZxMkhuiQgK6EDax90f4ajq4eMAtX5rVhoY/anLk742E7JRzZYsLzJqhHcaY1wHtYdJc6HRZ7c/b+QooLTI/S5fFZk8CuhC2sPt78PCDe1aZwOziBpf+A6Z+D1mHYe2b58qmbIKiXGg/uv7nbTsIPP3Nz5JyafYkoAtRX6WlcOAX6HgpOLuevy9qBHSbCHFfQOEZsy3xd1BOEDm8/ud2djFzu3j6m5uqolmTgC6ah1X/hgO/Ncyxj2yFM+nQqYrVqwbcCQXZsP0r8zphhVlGzsPXNue//EW449fz1yAVzZL8CxCOLzcTlr8Aq19rmOPvX2Za3B0vrXx/xGBzw3LT+5CXBUe2QPsxtju/hy8EdbTd8USTJQFdOL5DawANh9dX3uOkvvYtg/ABVfchVwoG3A5Ht8Ga/4AutU3+XIgL1BjQlVJtlVIrlFK7lFI7lVIPV1JmtFIqWykVZ3k82zDVFaIODq4yz6VFkLTatsfOOQppcRA9rvpyvSaDmzesed0s4hw+wLb1EALrWujFwGNa627AYOABpVRlt9P/0Fr3sTxm2rSWQtTHwVUQOQJcPCFhuW2PfeBX8xxdRf68jLsP9L7JtM4jh5leMELYWI0BXWudprXeYvk5B9gNhDV0xYSwiZxjkL7H5Lcjh0OCjW+M7lsGPm1qXpQCIOYOQFWdaxeinmqVQ1dKRQJ9gQ2V7B6ilIpXSv2olKp0hINS6m6lVKxSKjY9Pb3WlRWi1pL+MM9RI6HjJZBxAE4ess2xiwtNj5XocSZPXpPQbnD/eoi53TbnF+ICVgd0pZQ3sAh4RGt96oLdW4B2WuvewJvAt5UdQ2s9R2sdo7WOCQ4OrqyIELZ1cCW4+5ppaTuMNdtslXY58CsU5kB0LUZ4hnSp2FddCBuxKqArpVwxwfwzrfXXF+7XWp/SWp+2/PwD4KqUCrJpTYWoi4OrTKrFyRmCOkHLcNsE9H0/w6I7wD/q3BB+IezMml4uCvgA2K21frWKMq0s5VBKDbQcN8OWFRWi1k4eMpNWRY00r5UywTdxpVmyra62fgZf3ARB0XDHz+DmZZPqClFf1rTQhwG3AmPLdUu8Qil1r1LqXkuZScAOpVQ88AZwk9blV68Vwg7K58/LdLzEjNpM3Vz742kNq16B7+43x5y2FLxDbFNXIWygxgUutNargWrv+Git3wLeslWlhLCJg6ugRRCEdD23LWqUGdWZ8BtEDLL+WKUl8MMTEPsB9LwRJr4tXQ9FoyMjRYVjKi01qZWokef3QGkRYLZtnAOnrexpVZQHC28zwXzYw3DdexLMRaMkAV04pr0/wOmj0PXqivsmvGxmPvzxSeuO9fPfYc9SGP8SjJspk2CJRkv+ZQrHtPZN8IuArtdU3BfcGUY9CTu/NoG6OtmpsOVj6D8NBt9bfVkh7EwCunA8yRsheT0MfsDMF16ZYY9AaA9Y+piZAbEqa143w/WHP9owdRXChiSgi6ahtBSS1pjRmRc6fdzsL7P2DbN6UN8/V308Z1e45k04fQyW/vX895fJOQZbPoJeN4F/u/pfgxANTAK6aBo2z4UPr4A3+8Hmj0xg37cM5k6AV6Lh42vMup0ZCbB7CQy4A9y9qz9mWD8Y8zfYsQi+e8D0ZClv7RtQUggj/tpw1yWEDdXYbVEIuysugD9eNSkSZzf4/iH46RkoOmNGfg6+3wT5d4aa+VKcXWHgPdYde+TjJpD//iKUFsO175o0zZkTEDsXekyCwA4Ne31C2IgEdNH4bf0ETqWavt/tR5uW+fYvzayFPSdZAvhd8PU9cHgd9L0VfEKtP/7op0zPleXPQ8pG86WRl2W6K458vKGuSgibk4AuGrfiAvjjNbO6ffvRpk955/HmUV5Ae5j+I+xeXLe5VUY+YQYh7VsGLu7mET7A9IgRoomQgC4at62fwqkUmPhmzVPUOrtAj+vrfq6Y6eYhRBMlN0VF41VcaHLn4QNtu6iyEA5KArpovHZ9Z1rno5+ybgEJIZo5Ceii8TrwK7QIhPZj7V0TIZoECeiicdIaEn83syPK3ClCWEX+p4jGKX2PmVxLVgMSwmoS0EXjlLDCPMvNUCGsJgFdNE6JKyCgA/i1tXdNhGgyJKCLxqe40EzEJekWIWpFArpofFI2mXlaJN0iRK1IQBeNT+IKs+5n5HB710SIJkUCumh8En+HsP7g6WfvmgjRpEhAF41LXhakbpZ0ixB1IAFdNC6Jv5sl3+SGqBC1JgFdNB7FBbDiRbO4c/gAe9dGiCZHps8VDStls1nGrd2QmsuueR1O7IUpX5lFK4QQtdIkW+haa3tXQVhDa/j6Lph/i1n9pzonDsCqV6D79RA97uLUTwgHU2NAV0q1VUqtUErtUkrtVEo9XEkZpZR6Qyl1QCm1TSnVr2GqC6v2pXPJqyvJPFPJ6u/i4irKh9LSqvcf3w2ZCZCXCfHzqy6nNSx5BFw8YPws29dTiGbCmhZ6MfCY1robMBh4QCnV7YIyE4Boy+Nu4F2b1rKc1r4eHDxxhjmrEhvqFKImhWdgxb/g5Sj49bmqy+1eDCgI7Ajr36k6+G9bAEl/wLh/1G4tUCHEeWrMoWut04A0y885SqndQBiwq1yxicDH2uRC1iul/JRSrS3vtanoUB+u7tWGj9clceeIKIK83W19CqG1WVwCzHzknn5QmAt5J+FkEqz5D+SkQcsw2DgHhjwAPq0qHmfXYogYYpZ1+/ouM795p8vOL1NwGn55DsJioN+0hr4yIRxarW6KKqUigb7Ahgt2hQHJ5V6nWLbZPKADPDS2I0u2HWHOqkT+54quDXGK5m3PEvhyatX7w/rDDR+BdzC8GQNr34TLXzi/TEYCHN9pUijdrzNBe91bFQP66lfNNLk3fSbzngtRT1YHdKWUN7AIeERrfaouJ1NK3Y1JyRAREVGXQ0DqZjp+cx+z2l3Fi+uKuGtEe4J9pJVuU+veNl0Hb/rctMrzToKrF7TwB88A8I88tyRcrxth0wcw7BET4MvsXmyeu1xleqwMusekZ45uh1Y9zb6TSbD2Leg1GcJjLuYVCuGQrAroSilXTDD/TGv9dSVFUoHy85yGW7adR2s9B5gDEBMTU7euKsUF4OrBjWn/x6VO3uz5dCLBAweChy94+kNoT/AKrNOhzzq6w9zICx8Irh61e29uJhzdBhFDwcWtfvWoTv4pOPAL7PnB3HgsLTGpkqBomPASeIfU7bgpm+HwOtOyLgu81RnxmMmBr3sTxs08t33XYmjT79z0t/2nwsqXTUv9ylcgoD388iw4OcMl1eThhRBWqzGgK6UU8AGwW2v9ahXFFgMPKqXmA4OA7IbInwPQbijcvRIOrSV10b8YfPRz+P6z84po//acCu6HS+QQvKJHQFCnyhcZLsyF0iJwb2n2J280QefAL2a/i4fJAbfuBS6eJrjrUhO0804CCsL6msDv7AYb34O4L6A4D3zamNxy/6ng7lP19ez7GX56GnzDoMck6HaN+WIqU5QPJw+aFEbGATixHzL2Q+oWU/cWQdCmDzhZPsq9P0DSarh+Tt1GW657E9x9oe+frSsfFA09/gQb34ehD5sv06xkOLIFLv3HuXKe/jDyMfjtn/BGX5O2Sd0Mo//HXLsQot5UTX26lVLDgT+A7UBZN4X/ASIAtNazLUH/LWA8kAtM11rHVnfcmJgYHRtbbZEapZzM5b65f3Ai/RjBrvmMCVcEnNpJm5wd9FF7CVYmM5Tj5Mse957E0pW1RdGM8svgOo/NBKT9gSopQDu5ku/sjWfRSYrcAygdfD/ubXpSkvg7OmEFzicTUSXlukm6eEKLAPPXQu6Jc9ud3U0Kov1o2Pyh6bnh5g2h3U3gC+oMbQdCm76AguUzTf45qDOUFpuWtpMLePgB2nx55GWZn8t4h0JgtPki6XKVGVHp5Hxu/7Gd8OV0OLEPRj0FY56p+hdYWmqWegvpar7QTh6CN/rAkAfhsn9a/0Ec3wPvDDZBusefTE58zevwly0Q2OH8stkppkUf97n5i+Le1eDWwvpzCdHMKaU2a60rzVHWGNAbii0COphBRluTs/hqcwor9hynrX8L+kT40b21D/nH9lGatJagjM30KtlJaOmxs+87ogNY5z6c4yoQfSYDf3I4oMP4vGQs+coDT1dncgtLAHB2UvRs48OwKG+iQ3woVO4UlZRy8nQBJ1IO4HFsM055GaxvMRoXn1CCW7rTrXVLBrsl0jHte4qP7sY9KwHv4kwAip3cKfIIxDP3CLvCb+SnsAdp6eVNT6eDRGeswKMkBycnJ5ycFK4tQ1GBHSEgyqzgY80MhIVnYMmjJnDe9AV0uaKyXxws/SvEzoW2g+HyF2HHIvNXxsPbat9q3jDH9HjJ2G9eh3SH+9dW/x6tK//LSQhRJYcO6LWSdRiSN1LgHbQe6cAAABkCSURBVMb3GWF8sSkFT1dnLuseyrhuoXi4OLMtNZv45Cyy84rw9XSlpYcLJ04XsuFgBnHJWRSVnP/7CvPzpFOoN639PMnOLeLE6QLSsvM5nJl7XjkPVydigktpkx1H54LtdFLJfFEylh9KB+OkoLSKjyHYx50Bkf7EtAugT4QfXVu1xNPNufLC5RUXwpzRkJsBD2yo+EXw+0vw+4vQ9Wo4vB7OpIOTq+mR8qf/1uKXeoGTSZCwHFr3Ni12IYRNSUC3kbzCEo6eysfVWeHm7ISXuwte7pXfhsjOK2LXkVMkZ+bSuZUP3dq0xNXZdMvLyi0k8cQZvN1dCPFxx9fTlazcIg5l5nI4M5fT+cUUFpeQX1zK3qM5bDyYSWqWGTrvpCAqyIt+Ef6M6RLC8OggWnpUMe/Jka3w30ugzy0w8a1z22PnmhZ871vg2neg8DSs/g9sXwg3zzcpIiFEoyQB3QEcycpjR2o2u9JOsfPIKTYkZnAqvxgXJ8WoTsE8cmkneob7VnzjL8+ZgUA3LzDpjV2LIf5z6Hip6ZYok2AJ0aRIQHdAxSWlbE3O4rfdx5m/6TBZuUVc3j2Uv4yNpkdYucBelAezR5zLbbu3ND1pJrwMbl72qbwQos4koDu4nPwi5q5O4v0/EskpKKZb65Zc3y+MiX3CzKCro9th62emVR41smH7xwshGpQE9GYiK7eQb7em8s3WVOJTsvF2d2HOrf0Z2jHI3lUTQthIdQFdJs9wIH4t3Jg2LIrvHhzOz4+OpI2fB1PnbWRx/BF7V00IcRFIQHdQnUJ9+PKeofRt689DX2zl/T8SZWEQIRycBHQH5tvClY/vGMiEHq14fulups7bxJGsGlYOEkI0WRLQHZyHqzNv39KPmRO7E5uUyWWvreKTdUmcyi+yd9WEEDYmN0WbkcMZuTy1aBvrEjNwcVL0b+fP0A5BuDgrikpKcXFSTOrflla+tZxhUghx0UgvF3FWaalm8+GTrNhznBV709mddv7U9h6uTtwzsgP3jGpPC7darX8ihLgIJKCLKuUVluDkBK5OTqRm5fHST3tYsi2NEB93XryuJ5d2kzU+hWhMpNuiqJKnmzPuLs44OSnaBrTgrVv6sei+IQR6u3Pnx7H8/dvt5FlmnRRCNG4S0EUF/dsF8O0DQ7lrRBSfrj/MVW/+wc4j2faulhCiBhLQRaXcXZz525Xd+PSOQeTkF3Pd22v5YPVB6csuRCMmAV1Ua3h0ED89MpKRnYL455JdTP9wE7FJmZKGEaIRkm4MokYBXm7897YYPll/iOeX7ub3vek4OymiQ7y5rFsotwxqJ10dhWgEpJeLqJWM0wVsOZxFfHIWmw+dZP3BDJyU4vLuoVzWrRXRod50CPbGw9WKVZWEELVWXS8XaaGLWgn0dmdcN7NkH8ChjDN8tuEwCzYl88P2o4BZVWlslxBevK4nIS1Ny/1IVh5PfrWNwpJSvrhrMM5OspaoELYmLXRhE0UlpRw8cYZ9x3LYnprNR2uT8HB15l/X9QTgqUXbyCsqoahE8+9Jvbghpq2dayxE0yQDi8RFl5B+mr8uiCM+xXR37B3uy39u6sujC+JIy85jxeOjZSSqEHUgA4vERdch2Juv7hvKk+M789dxnfjy3qFEBXnx9yu7cuxUAe//cdDeVRTC4UgTSTQYV2cn7h/d8bxtMZEBTOjRitkrE7hpQNuzOXYhRP1JC11cdE+N70JRSSkv/bRXBioJYUMS0MVFFxnkxe3Do1i0JYUHPt8ic7MLYSMS0IVdPHV5F56Z0IVlO49x9Zur2ZEqc8UIUV81BnSl1Fyl1HGl1I4q9o9WSmUrpeIsj2dtX03haJycFPeM6sCCuwdTUFTKtW+v4fklu8jOk9a6EHVlzU3RD4G3gI+rKfOH1voqm9RINCsxkQH88PAIXv5pDx+sOcg3W1O5b3QHOoR4E+TlTpi/JwFebvauphBNQo0BXWu9SikV2fBVEc1VgJcbs/7Uiz8PbseM73fy/NLdZ/e5OCn+fUMvrusbbscaCtE02Krb4hClVDxwBHhca72zskJKqbuBuwEiIiJsdGrhKHqE+bLwniEkZ+aRfrqAzDOFzF19kL8ujCe3sIQpg9rZu4pCNGq2COhbgHZa69NKqSuAb4HoygpqrecAc8CMFLXBuYWDUUoREdiCiMAWAIyIDuL+z7bwt292kJVbxOXdW9HCzRk3FycyzxRy/FQB2XlFXNI1RCYEE82eVUP/LSmXJVrrHlaUTQJitNYnqisnQ/+FtQqLS3l0QRxLt6dVWWbKoAhesMwbI4Qja9DZFpVSrYBjWmutlBqI6TmTUd/jClHGzcWJN27uy+QBbTmZW0huYQkFRSX4e7kR4uPB0u1H+HT9Ya7s2ZqhHYPsXV0h7KbGgK6U+gIYDQQppVKA5wBXAK31bGAScJ9SqhjIA27SMvxP2Jizk2Jkp+BK9/Vp68fq/Sd46uttLHtkpEz6JZotmW1ROIQNiRlMnrOeaUMj+cc13e1dHSEajMy2KBzeoPaBTB3Sjo/WJbFqX7q9qyOEXUhAFw7jyfFd6BTiw50fx/LrrmP2ro4QF50EdOEwvNxd+OLuwXRp5cO9n27mu7hUe1dJiItKArpwKAFebnx25yD6tfPnkQVxLIxNtneVhLhoJKALh+Pj4crHtw9keMcgnl60jaXbqu6/LoQjkYAuHJKHqzPv3dqffhH+PLJgKyv2HLd3lYRocBLQhcNq4ebC3OkD6GzJqa/YK0FdODYJ6MKhtfRw5aPpA4kK8mL6vE089dU2mXNdOCwJ6MLhBXq78+0Dw7h3VAe+2pLCuFdXsi5BZqcQjkcCumgWPFydeXpCF769fxhe7i48uiCOvMISe1dLCJuSgC6alZ7hvsy6vidHT+Uzb+1Be1dHCJuSgC6anUHtA7m0awjvrkgg80yhvasjhM1IQBfN0lPju3CmsJi3lh+wd1WEsBkJ6KJZig714Yb+bflkfRLJmbn2ro4QNiEBXTRbj47rhLOT4m/f7qCgWG6QiqZPArpotlr5evC/V3Vj1b507v54s/R6EU2eLO0imrUpg9rh4qR4+uvtTJ23kddv6sORrHz2Hcsh2NudS7uF2ruKQlhNArpo9iYPiMDTzYW/LohjyL+Wn93upODLe4fQv12AHWsnhPUkoAsBXNO7Da1aerDl8Ek6BnsTEdiC6fM28djCeH54eISsUyqaBMmhC2ExMCqAe0d14NJuoXQK9eGVG3qTlJHLrB/32LtqQlhFAroQVRjSIZDbh0Xx8bpDrN5/wt7VEaJGEtCFqMaT4zvTIdiLx7+M59ipfHtXR4hqSUAXohoers68cXNfTuUXcfuHmzhTUGzvKglRJQnoQtSgextf3r6lH3uO5vDg51soLim1d5WEqJQEdCGsMKZLCDMndmfF3nT+9s0OcgulpS4aH+mLJYSVpgxqR+rJPN75PYFfdh/jjuFR/HlwO3w9Xe1dNSEAUFrr6gsoNRe4Cjiute5RyX4FvA5cAeQC07TWW2o6cUxMjI6Nja1TpYWwp01Jmby94gC/703H09WZYR0DGdkpmNGdQogIbGHv6gkHp5TarLWOqXSfFQF9JHAa+LiKgH4F8BdMQB8EvK61HlRTpSSgi6ZuR2o28zcdZuW+dJIz8wCY1D+cp8Z3IdjH/Ww5rTWm3SNE/VUX0GtMuWitVymlIqspMhET7DWwXinlp5RqrbVOq1NthWgieoT58nxYT7TWJGXkMn/TYeauPsiyHUe5fXgU2XlFxB7K5GD6Ge4c0Z6HL4nGyUkCu2g4trgpGgYkl3udYtlWgVLqbqVUrFIqNj093QanFsL+lFJEBXnxzISuLHtkJP0j/Xn9t/3M33QYb3cXBkYF8Ppv+7nvs82clm6PogFd1JuiWus5wBwwKZeLeW4hLob2wd7MmzaAI9n5hPi44+rshNaauWuSeGHpLv70zlrmTR9AGz9Pe1dVOCBbtNBTgbblXodbtgnRLCmlCPPzxNXZ6ezrO4ZH8fHtgziSlce9n26WBTVEg7BFQF8M3KaMwUC25M+FqGh4dBD/d2NvtqVkM/P7XfaujnBANaZclFJfAKOBIKVUCvAc4AqgtZ4N/IDp4XIA021xekNVVoim7rLurbh3VAdmr0ygfzt/ru8Xbu8qCQdiTS+Xm2vYr4EHbFYjIRzc45d1Ii75JP/zzXYyzxTStXVLOoX6nNfVsUxWbiEers54uDrboaaiqZGRokJcZC7OTrx5cz9umrOO55fuPrs9xMed3m396B3uS8aZQtYlZLDnaA79IvxYeM8QXJxlpg5RvRoHFjUUGVgkmjutNemnC9h/7DR7juawMzWbuJQsEtPP4O7iREykP239WzB/UzJPT+jCvaM62LvKohGo18AiIUTDUEoR4uNBiI8HwzoGnd2ek1+Em4sT7i7OaK05mVvIq7/s49KuIXQM8bFjjUVjJ3/DCdHI+Hi44u5icuZKKZ6/tict3Jx5/MttlJTK8A1RNQnoQjRywT7uzLimO3HJWbz80x7yi6QPu6icBHQhmoBrerfh2j5teG9VIiNfXsF7KxPIyS+yd7VEIyM3RYVoIrTWrE3I4J3fD7DmQAauzore4X4Mah/A+O6t6Rnua+8qiougXtPnNhQJ6ELUXXxyFj/uOMr6xAy2p2ajgE/uGMSQDoH2rppoYNLLRQgH07utH73b+gFw8kwhN7y3jvs+28w39w8jKsjLzrUT9iI5dCGaOH8vN+ZOHYAC7vhwE1m5hfaukrATCehCOICIwBbMuS2GlJN5TJ23iZ92pJFXKL1hmhtJuQjhIAZEBvDq5N48+91O7v10Cy3cnBkZHUy/dn70CvejR5gv3u7yX96RyacrhAO5qlcbxndvxYaDmSzdnsbKven8tPMoAG4uTjwwuiP3jm5/duCScCwS0IVwMC7OTgzrGHR2OoETpwvYnprNos0pvPbrPhbHp/LidT0Z1F56xDgayaEL4eCCvN0Z0zmEt27px7zpAygoLmXynPU8tjCeE6cLrDrGpqRMTp6Rm62NnQR0IZqRMZ1D+OXRUdw3ugOL41MZ+8rvfLQ2if3HcsjOK+LCcSn5RSU88/U2bpi9jinvb+CMLHLdqMnAIiGaqQPHc/jfb3eyLjHj7DZPV2diIv0Z3TmErq19mPn9LvYczWFinzZ8H3+ES7qG8t6f++PkpOxY8+ZNBhYJISroGOLD53cNYmtyFsmZuaTnFJByMo8/9qfzzyVmzVP/Fq7Mmz6AMZ1D6NPWjxnf7+KlZXt4ZkLXao+ttUYpCfoXmwR0IZoxpRT9IvzpF+F/3vbDGblsPpzJkPZBtPL1AGDa0EgS0k/z3spEtDav2/h5AlBSqolLPsmGg5lsOXSSLYezaOPnwbtT+tM2oMVFv67mSlIuQgirFZWU8sSX8XwXfwQFjO0SiqebM6v2pZOdZ2Z/bB/sRZ9wP37dfQw3F2fmTouhV7iffSvuQGRyLiGETSVn5vL5xsMs3JSMUopRnYIZ0yWYoR2CCPByA0yOftq8TZw4XcDMa3owukswIT4edq550ycBXQjRIMriR1X58vScAu78aBPxKdkAtPb1YGBUAJP6hzOsQxBOTupsuiblZB4TerTGzUU631VHAroQwm6KSkqJT84iPiWb+OQsVu1PJyu3iHB/T/q382fNgROcOG36uPdp68ebN/eVvHs1JKALIRqNguISlu08xvyNh9lzNIdhHYMY1y0UrTV//2YHSsFzV3cnyMed46fyKSgu5dq+YTIPjYUEdCFEk3A4I5e/fLHlbIqmTNfWLZk7LYbWvqZXTWL6aeasSmRS/3BiIgMqHCfpxBkWxCazOO4InVv58O9JvQj0dr8o19DQJKALIZqMwuJS1iVm4OXmTIiPB/uP5/Dw/Di83J15Z0p/Vu49zuyViRSWlOLu4sQ7U/pxSddQABLSTzPz+12s3JeOs5NiaIdANhzMJMjLjben9KPvBd0zm6J6B3Sl1HjgdcAZeF9rPeuC/dOAfwOplk1vaa3fr+6YEtCFENbac/QUt8/bxJHsfACu7dOG+8d05Ikv49lx5BQvXteDo9kFvL3iAB6uTtw1oj03DmhLaEsPdqRmc++nmzl2Kp87R7Tn8u6t6BXm22RHu9YroCulnIF9wDggBdgE3Ky13lWuzDQgRmv9oLWVkoAuhKiN46fyef23/VzZszVDLTNJni4o5p5PYllzwExfcFWv1jx7dbcK3SOzcgt5etF2ft51lFINgV5uxET60y7Qi4iAFvRv50/X1i0v+jXVRX0D+hDgH1rryy2vnwHQWv+rXJlpSEAXQthBQXEJ76xIoE+EH2M6h1Rb9uSZQlbtT2f5nuPsPHKKw5m5FBaXohTcPDCCpy7vgm8L1/PeU1xSyqfrD/HbnuP0i/BnTJcQu7bw6xvQJwHjtdZ3Wl7fCgwqH7wtAf1fQDqmNf+o1jq5kmPdDdwNEBER0f/QoUN1uiAhhLCF0lLN0VP5zF19kHlrk/Bv4coDYzrSM8yX9sHeHDxxmr9/u5PdaadoG+BJysk8tKWFP6pzMJd0CWV4dBAtPVwu2tw1FyOgBwKntdYFSql7gMla67HVHVda6EKIxmTnkWz+9s0O4pKzztve2teDZ6/qxvgerTiZW8SqfaaFv7LcdAcArs4KT1dn7h/TkbtHtD/bgt915BT/9/Neru8XzpW9Wte7ng2ecrmgvDOQqbX2re64EtCFEI2N1ppDGbkknjhNYvoZAG4ZFEELt4p94ItLStmanMXGg5kUFJVQXKrZnXaKFXvTGdI+kJf+1ItFW1J4e8UBSrRGAS9P6s2k/uH1qmN9A7oLJo1yCaYXyybgFq31znJlWmut0yw/Xwc8pbUeXN1xJaALIRyN1povY1P4x/c7yS0sAUyPnCfHd+HJr7ax+sAJXriuB1MGtavzOeo1H7rWulgp9SCwDNNtca7WeqdSaiYQq7VeDDyklLoGKAYygWl1rq0QQjRRSiluHNCWAVEBvPHbfq7o2Zpx3Uwf+fenxnD/Z1v42zc7KCouZdqwKNufXwYWCSHExVFYXMrjX8ZzXd8wxnSpvkdOVWTFIiGEaATcXJx44+a+DXZ8madSCCEchAR0IYRwEBLQhRDCQUhAF0IIByEBXQghHIQEdCGEcBAS0IUQwkFIQBdCCAdht5GiSql0oK7z5wYBJ2xYnaaiOV53c7xmaJ7X3RyvGWp/3e201sGV7bBbQK8PpVRsVUNfHVlzvO7meM3QPK+7OV4z2Pa6JeUihBAOQgK6EEI4iKYa0OfYuwJ20hyvuzleMzTP626O1ww2vO4mmUMXQghRUVNtoQshhLiABHQhhHAQTS6gK6XGK6X2KqUOKKWetnd9GoJSqq1SaoVSapdSaqdS6mHL9gCl1C9Kqf2WZ39717UhKKWclVJblVJLLK+jlFIbLJ/5AqWUm73raEtKKT+l1FdKqT1Kqd1KqSHN4bNWSj1q+fe9Qyn1hVLKwxE/a6XUXKXUcaXUjnLbKv18lfGG5fq3KaX61eZcTSqgK6WcgbeBCUA34GalVDf71qpBFAOPaa27AYOBByzX+TTwm9Y6GvjN8toRPQzsLvf6JeA1rXVH4CRwh11q1XBeB37SWncBemOu3aE/a6VUGPAQEKO17oFZr/gmHPOz/hAYf8G2qj7fCUC05XE38G5tTtSkAjowEDigtU7UWhcC84GJdq6TzWmt07TWWyw/52D+g4dhrvUjS7GPgGvtU8OGo5QKB64E3re8VsBY4CtLEYe6bqWULzAS+ABAa12otc6iGXzWmCUwPZVSLkALIA0H/Ky11quAzAs2V/X5TgQ+1sZ6wE8p1draczW1gB4GJJd7nWLZ5rCUUpFAX2ADEKq1TrPsOgqE2qlaDek/wJNAqeV1IJCltS62vHa0zzwKSAfmWdJM7yulvHDwz1prnQq8AhzGBPJsYDOO/VmXV9XnW68Y19QCerOilPIGFgGPaK1Pld+nTX9Th+pzqpS6Cjiutd5s77pcRC5AP+BdrXVf4AwXpFcc9LP2x7RGo4A2gBcV0xLNgi0/36YW0FOBtuVeh1u2ORyllCsmmH+mtf7asvlY2Z9flufj9qpfAxkGXKOUSsKk08Zi8st+lj/LwfE+8xQgRWu9wfL6K0yAd/TP+lLgoNY6XWtdBHyN+fwd+bMur6rPt14xrqkF9E1AtOVOuBvmJspiO9fJ5ix54w+A3VrrV8vtWgxMtfw8FfjuYtetIWmtn9Fah2utIzGf7XKt9RRgBTDJUsyhrltrfRRIVkp1tmy6BNiFg3/WmFTLYKVUC8u/97LrdtjP+gJVfb6LgdssvV0GA9nlUjM101o3qQdwBbAPSAD+Zu/6NNA1Dsf8CbYNiLM8rsDkk38D9gO/AgH2rmsD/g5GA0ssP7cHNgIHgC8Bd3vXz8bX2geItXze3wL+zeGzBmYAe4AdwCeAuyN+1sAXmPsERZi/yO6o6vMFFKYnXwKwHdMLyOpzydB/IYRwEE0t5SKEEKIKEtCFEMJBSEAXQggHIQFdCCEchAR0IYRwEBLQhRDCQUhAF0IIB/H/zEz8iYsz6EAAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NHtK2GIbZk6t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_Subtask3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}